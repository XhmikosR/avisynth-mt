<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<html lang="ru">
<head>
<meta http-equiv="Content-Language" content="ru">
   <meta http-equiv="Content-Type" content="text/html; charset=windows-1251">
   <meta name="Author" content="Wilbert Dijkhof">
   <title>ConditionalFilter Avisynth Filter</title>
   <link rel="stylesheet" type="text/css" href="../../avisynth.css">
<!--
Automatically generated, don't change:
$Id: conditionalfilter.htm,v 1.8 2008/12/10 18:52:28 fizick Exp $
-->
</head>
<body>
<h2>
<a NAME="ConditionalFilter"></a>ConditionalFilter
</h2>
<p><code>ConditionalFilter </code>(<var>clip testclip, clip source1, clip source2,
string expression1, string operator, string expression2, bool &quot;show&quot;</var>)
<p><code>ConditionalFilter</code> – условный фильтр – проверяет для каждого кадра условие,
образуемое "expression1+operator+expression2" (выражение1+оператор+выражение2), 
и возвращает кадры клипа <var>source1</var>, когда условие выполняется, 
в противном случае возвращаются кадры клипа <var>source2</var>.
Если в вызове некоторой функции в выражениях <var>expression1</var> или <var>expression1</var> 
явным образом не задан клип, то она применяется к клипу
<var>testclip</var>. Звук берётся из клипа <var>source1</var>.
<p>Пример: выбираем кадры из клипа vid_blur, если средняя яркость кадра меньше 20, иначе
берём кадры клипа vid.

<pre>vid = AviSource(&quot;file&quot;)
vid_blur = vid.Blur(1.5)
ConditionalFilter(vid, vid_blur, vid, &quot;AverageLuma()&quot;, &quot;lessthan&quot;, &quot;20&quot;)</pre>
<p>Параметр <var>show</var>=&quot;true&quot; включает вывод на экран текущих значений выражений для каждого кадра.
</p>
<p>Строковые (неименованные) параметры <var>expression1</var> и <var>expression2</var> могут быть 
любыми численными или логическими выражениями и могут включать внутренние или пользовательские функции, а также
некоторые предопределённые функции (<a href="#RuntimeFunctions">функции времени исполнения (Runtime)</a>)
и специальную переменную времени исполнения <var>current_frame</var> (номер запрашиваемого кадра).
<br>
Строка <var>operator</var> может принимать значения &quot;equals&quot; (равно), &quot;greaterthan&quot; (больше) или "lessthan" (меньше).
Или соответственно "=", "&gt;" и "&lt;".
</p>
<h2><a NAME="ScriptClip"></a>ScriptClip
</h2>
<p><code>ScriptClip </code>(<var>clip, string filter, bool &quot;show&quot;, bool
&quot;after_frame&quot;</var>)
<p><code>ScriptClip</code> выдаёт клип, возвращаемый фильтром <var>filter</var>, применяемым для каждого кадра.
Строковый параметр <var>filter</var> может быть любым выражением, возвращающим клип, 
включая встроенные или пользовательские клиповые функции, 
и может включать переносы строк (позволяющие выполнение последовательности команд). 
Также, некоторые предопределённые
функции (<a href="#RuntimeFunctions">функции времени исполнения (Runtime)</a>) 
и специальная переменная времени исполнения <var>current_frame</var> (номер запрашиваемого кадра) 
могут быть использованы в выражении для <var>filter</var>.
<p>Параметр <var>show</var>=&quot;true&quot; включает вывод значения параметра на каждом кадре.
</p>
Примеры: <br>
<pre># печатает разницу между этим и предыдущим кадром поверх текущего кадра
clip = AviSource(&quot;c:\file.avi&quot;)
ScriptClip(clip, &quot;Subtitle(String(YDifferenceFromPrevious))&quot;)

# Применяет размытие для каждого кадра в зависимости от разницы с предыдущим кадром
# Также показывает, как на некоторые кадры накладывается сообщение об ошибке
clip = AviSource(&quot;c:\file.avi&quot;)
ScriptClip(clip, &quot;Blur(YDifferenceFromPrevious/20.0)&quot;)

# Применяет temporalsoften на достаточно статичных сценах, и <u>меняющееся</u> размытие на динамичных.
# Также производится присваивание переменной – поэтому вставлен символ разрыва строки
function fmin(float f1, float f2) {
&nbsp; return (f1&lt;f2) ? f1 : f2
}
clip = AviSource(&quot;c:\file.avi&quot;)
ScriptClip(clip, &quot;diff = YDifferenceToNext()&quot;+chr(13)+&quot;diff &gt; 2.5 ? Blur(fmin(diff/20,1.5)) : TemporalSoften(2,7,7,3,2)&quot;)

# Показывает номер кадра
ScriptClip(&quot;subtitle(string(current_frame))&quot;)

# Показывает строку 'frame = номер кадра'
ScriptClip(&quot;&quot;&quot;subtitle(&quot;frame = &quot; + string(current_frame))&quot;&quot;&quot;)</pre>

<p>В версии v2.55 добавлен параметр <i><var>after_frame=true/false</var></i>. 
Он определяет, должен ли скрипт вычисляться до (по умолчанию) или после того, как кадр
будет получен от вышерасположенных фильтров (см. <a href="#AdvancedFiltering">объяснение</a>).</p>

<p>Ограничения: результат работы фильтра <code>ScriptClip</code> должен быть такого же формата, как входной клип 
<var>clip</var> (те же ширина, высота и цветовой формат). Возвращаемый клип может иметь другую длину, но будет 
использоваться длина исходного клипа. Звук из исходного клипа возвращается без изменений.
Для двух сильно отличающихся источников (MPEG2DEC3 and AviSource) может получиться несовпадение цветовых пространств
– это известная "фишка".

<h2><a NAME="FrameEvaluate"></a>FrameEvaluate
</h2>
<p><code>FrameEvaluate </code>(<var>clip clip, script filter, bool "after_frame"</var>)
<p>Действует аналогично <code>ScriptClip</code>, но результат работы <var>filter</var> игнорируется –
возвращаются кадры из исходного клипа. Это полезно, например, для присваивания переменных в теле функции.
<br>
  В версии v2.53 добавлен параметр <var>after_frame</var>=<code>true/false</code>.
Он определяет, должен ли скрипт вычисляться до (по умолчанию) или после того, как кадр
будет получен от вышерасположенных фильтров.</p>

<h2><a name="ConditionalReader"></a>ConditionalReader</h2>
<p>Этот фильтр позволяет считывать произвольную информацию из файла в некоторую переменную.
<p>Описание находится на <a href="conditionalreader.htm">отдельной странице</a>.</p>

<h2><a NAME="RuntimeFunctions"></a>Функции времени исполнения (Runtime)
</h2>
<p>Это встроенные функции, вычисляемые на каждом конкретном кадре.

<p>Возвращают среднее по всем пискелям кадра значение выбранной составляющей (яркости или цветности).
Требуется цветовой формат YV12, наличие поддержки ISSE в процессоре):
<br>
  <code>AverageLuma </code>(<var>clip</var>)<br>
  <code>AverageChromaU </code>(<var>clip</var>)<br>
  <code>AverageChromaV </code>(<var>clip</var>)

<p>Возвращают действительное число от 0 до 255, являющееся модулем разности между цветовыми (или яркостными)
плоскостями длух клипов (требуется YV12, ISSE):
<br>
  <code>RGBDifference </code>(<var>clip1, clip2</var>)<br>
  <code>LumaDifference </code>(<var>clip1, clip2</var>)<br>
  <code>ChromaUDifference </code>(<var>clip1, clip2</var>)<br>
  <code>ChromaVDifference </code>(<var>clip1, clip2</var>)
<p>При использовании этих функций работает соглашение "implicit last", т.е. если первый параметр
пропущен, то подразумевается последний упомянутый клип; в данном случае это входной <var>testclip</var>, 
передаваемый фильтрам ConditionalFilter, ScriptClip, FrameEvaluate.

<p>Нижеследующие фильтры полезны для определения смены сцены (или смены плана, в общем, когда кадр существенно
отличается от предыдущего или следующего):
<br>
  <code>RGBDifferenceFromPrevious </code>(<var>clip</var>)<br>
  <code>YDifferenceFromPrevious </code>(<var>clip</var>)<br>
  <code>UDifferenceFromPrevious </code>(<var>clip</var>)<br>
  <code>VDifferenceFromPrevious </code>(<var>clip</var>)<br>
  <code>RGBDifferenceToNext </code>(<var>clip</var>)<br>
  <code>YDifferenceToNext </code>(<var>clip</var>)<br>
  <code>UDifferenceToNext </code>(<var>clip</var>)<br>
  <code>VDifferenceToNext </code>(<var>clip</var>)<br>
  &nbsp;
<pre># Заменяет последний кадр перед сменой сцены на первый после неё:
ConditionalFilter(last, last, last.trim(1,0), &quot;YDifferenceToNext()&quot;, &quot;&gt;&quot;, &quot;10&quot;, true)</pre>

<h4>Прочие встроенные функции:</h4>
<p><code>YPlaneMax </code>(<var>clip, float threshold</var>)<br>
  <code>UPlaneMax </code>(<var>clip, float threshold</var>)<br>
  <code>VPlaneMax </code>(<var>clip, float threshold</var>)<br>
  <code>YPlaneMin </code>(<var>clip, float threshold</var>)<br>
  <code>UPlaneMin </code>(<var>clip, float threshold</var>)<br>
  <code>VPlaneMin </code>(<var>clip, float threshold</var>)<br>
  <code>YPlaneMedian </code>(<var>clip</var>)<br>
  <code>UPlaneMedian </code>(<var>clip</var>)<br>
  <code>VPlaneMedian </code>(<var>clip</var>)<br>
  <code>YPlaneMinMaxDifference </code>(<var>clip, float threshold</var>)<br>
  <code>UPlaneMinMaxDifference </code>(<var>clip, float threshold</var>)<br>
  <tt><code>VPlaneMinMaxDifference </code></tt>(<i><var>clip, float threshold</var></i>)
<p>порог <var>Threshold</var> (в процентах) определяет, какая доля пикселов может быть меньше (больше)
минимума (необязателен; по умолчанию 0).

<p>Если предшествующий раздел понятен, можно переходить к разделу углублённого изучения, 
который поведает о дополнительных возможностях условного фильтрования.

<a name="AdvancedFiltering"></a>
<h2>Углублённое изучение условного фильтрования: часть I</h2>
<p>
Для понимания этого раздела требуется небольшое пояснение принципа работы AviSynth:
<br>
Скрипты обрабатываются сверху вниз, но когда приложение-клиент запрашивает кадр, 
его вычисление начинается с последнего кадра и продолжается вверх по цепочке фильтров.
Пример: </p>
<pre>AviSource(&quot;myfile.avi&quot;)
ColorYUV(analyze=true)
Histogram()</pre>

При открытии скрипта, положим, в VirtualDub'е, происходит следующее:
<ul>
<li>
Когда Vdub запрашивает кадр, AviSynth запрашивает кадр у фильтра Histogram.</li>

<li>
Histogram запрашивает кадр у ColorYUV,</li>

<li>
ColorYUV – у AviSource, который создаёт кадр (читая его из файла) и отдаёт его ColorYUV.</li>

<li>
ColorYUV обрабатывает кадр и отдаёт его фильтру Histogram, который, в свою очередь, возвращает
результат работы в Vdub.</li>
</ul>
Т.о. цепочка фильтров работает, фактически, снизу вверх 
(кадры вытягиваются из нижнего фильтра, а не выталкиваются из верхнего), 
что даёт возможность каждому фильтру использовать несколько кадров
из вышележащих фильтров для получения запрашиваемого кадра.
<p>Условные фильтры, однако, должны вычислять скрипт <u>до</u> того, как они запрашивают кадры из вышележащих
фильтров, т.к. им требуется знать, какой фильтр нужно вызвать.
Другая важная особенность состоит в том, что только глобальные переменные (определённые ключевым словом
<code>global</code>) могут использоваться и внутри, и снаружи условного фильтра. Пример:

<pre>v = AviSource(&quot;E:\Temp\Test3\atomic_kitten.avi&quot;).ConvertToYV12

function g(clip c)
{
&nbsp; <b>global</b> <b>w</b> = c
&nbsp; c2 = ScriptClip(c, &quot;subtitle(t)&quot;)
&nbsp; c3 = FrameEvaluate(c2, &quot;t = String(text)&quot;)
&nbsp; c4 = FrameEvaluate(c3, &quot;text = YDifferenceFromPrevious(<b>w</b>)&quot;)
&nbsp; return c4
}

g(v)</pre>
Эта цепочка фильтров работает следующим образом:
<ul>
<li>
Когда Vdub запрашивает кадр, AviSynth запрашивает его у функции g().</li>

<li>
g() запрашивает кадр у AviSource():</li>

<ul>
<li>
AviSynth запрашивает кадр у второго оператора FrameEvaluate.</li>

<li>
Второй FrameEvaluate вычисляет <i>YDifferenceFromPrevious(w)</i> и присваивает это значение переменной
<i>text</i>, после получения кадра из AviSource. 
После этого запрашивается кадр у первого оператора FrameEvaluate.</li>

<li>
Первый FrameEvaluate запрашивает кадр у ScriptClip <u>после</u> вычисления <i>String(text)</i>
и присваивания этого значения переменной <i>t</i>.</li>

<li>
ScriptClip запрашивает кадр у ConvertToYV12(), потом вызывает <i>Subtitle(t)</i> для этого кадра.</li>

<li>
ConvertToYV12() запрашивает кадр у AviSource().</li>
</ul>

<li>
AviSource() создаёт кадр и отдаёт его функции g(), которая возвращает его в Vdub.</li>
</ul>

Как видно, <b>w</b> определена как глобальная переменная. Таким образом, мы можем её использовать в дальнейшем 
в условных фильтрах. Если мы хотим использовать переменные <b>t</b> и <b>text</b> в других функциях 
(внутри или вне условных фильтров), их тоже надо определить как глобальные. К примеру:
<pre>v = AviSource(&quot;E:\Temp\Test3\atomic_kitten.avi&quot;).ConvertToYV12

function g(clip c)
{
&nbsp; global w = c
&nbsp; c2 = ScriptClip(c, &quot;subtitle(<b>t</b>)&quot;)
&nbsp; c3 = FrameEvaluate(c2, &quot;me()&quot;)
&nbsp; c4 = FrameEvaluate(c3, &quot;<b>global</b> <b>text</b> = YDifferenceFromPrevious(w)&quot;)
&nbsp; return c4
}

function me()
{
&nbsp; <b>global</b> <b>t</b> = String(<b>text</b>)
}

g(v)</pre>

Большая часть написанного для иллюстрации скрипта избыточна: следующие два скрипта выдают тот же самый результат.
<pre>v = AviSource(&quot;c:\clip.avi&quot;)
# ScriptClip принимает и многострочные скрипты:
Scriptclip(v,&quot;
	text = YDifferenceFromPrevious()
	t = string(text)
	subtitle(t)
&quot;)</pre>

<pre>v = AviSource(&quot;c:\clip.avi&quot;)
ScriptClip(v, &quot;Subtitle(String(YDifferenceFromPrevious))&quot;)
</pre>
В следующем разделе мы научимся записывать в текстовый файл информацию, зависящую от кадра.

<h2>
Углублённое изучение условного фильтрования: часть II</h2>

<p>В следующем примере в текстовый файл записывается некоторая информация, зависящая от кадра.
Первая переменная &quot;a&quot; говорит о том, имеется ли в кадре "гребёнка" (combing), для её 
определения используется фильтр <code>IsCombed</code> из пакета <code>Decomb</code>. Вторая переменная
&quot;b&quot; говорит о том, много ли движения в кадре.</p>

<pre>global sep=&quot;.&quot;
# пороговое значения для определения "гребёнки"
global combedthreshold=25

function IsMoving()
{
global b = (diff &lt; 1.0) ? false : true
}

function CombingInfo(clip c)
{
file = &quot;F:\interlace.log&quot;
global clip = c
c = WriteFile(c, file, &quot;a&quot;, &quot;sep&quot;, &quot;b&quot;)
c = FrameEvaluate(c, &quot;global a = IsCombed(clip, combedthreshold)&quot;)
c = FrameEvaluate(c, &quot;IsMoving&quot;)
c = FrameEvaluate(c,&quot;global diff = 0.50*YDifferenceFromPrevious(clip) + 0.25*UDifferenceFromPrevious(clip) + 0.25*VDifferenceFromPrevious(clip)&quot;)
return c
}

v = mpeg2source(&quot;F:\From_hell\from_hell.d2v&quot;).trim(100,124)
CombingInfo(v)</pre>
<p>Мы можем и упростить эти две функции, и удалить глобальные переменные, записав их следующим образом:</p>
<pre>function IsMoving(float diff)
{
 return (diff &gt;= 1.0)
}

function CombingInfo(clip c)
{
 file = &quot;F:\interlace.log&quot;

 c = WriteFile(c, file, &quot;a&quot;, &quot;sep&quot;, &quot;b&quot;)
 c = FrameEvaluate(c,&quot;
       diff = 0.50*YDifferenceFromPrevious() + 0.25*UDifferenceFromPrevious() + 0.25*VDifferenceFromPrevious()
       b = IsMoving(diff)
       a = IsCombed(combedthreshold)
     &quot;)

 return c
}</pre><p>
В следующем разделе мы рассмотрим пример адаптивной фильтрации/масштабирования.</p>

<h2>
Углублённое изучение условного фильтрования: часть III</h2>

<p>
На форумах (имеется в виду doom9 - прим.перев.) было придумано некоторое количество 
адаптивных по движению фильтров масштабирования и сглаживания.
Эти фильтры различают малое, среднее и большое количество движения в клипе (на основе
покадрового сравнения) и применяют различные группы фильтров в зависимости от этого.
Как правило, имеет смысл использовать временнУю фильтрацию в статичных сценах,
пространственную фильтрацию в динамичных сценах, и их комбинацию в промежуточном случае.

<br>Ниже нажодится упрощённая версия фильтра QUANTIFIED MOTION FILTER v1.5 b1 (10/07/2003)
от HomiE FR:</p>
<pre>---------------------------------------------------- 
# QUANTIFIED MOTION FILTER v1.3 
# Загружаем плагины AviSynth
LoadPlugin(&quot;C:\PROGRA~1\GORDIA~1\mpeg2dec3.dll&quot;) 
LoadPlugin(&quot;C:\PROGRA~1\GORDIA~1\TemporalCleaner.dll&quot;) 
LoadPlugin(&quot;C:\PROGRA~1\GORDIA~1\FluxSmooth.dll&quot;) 
LoadPlugin(&quot;C:\PROGRA~1\GORDIA~1\UnFilter.dll&quot;)

# Загружаем скрипт QUANTIFIED MOTION FILTER (текст файла ниже)

Import(&quot;E:\temp\QMF\qmf.avs&quot;)

# Фильтрация для малого количества движения
# -&gt; масштабирование с повышенной резкостью и временнАя фильтрация
function Low_Motion_Filter(clip c)
{
&nbsp; c = TemporalCleaner(c, 5, 10)
&nbsp; c = LanczosResize(c, 512, 272)
&nbsp; return c
}

# фильтрация для среднего количества движения
# -&gt; нейтральное бикубическое масштабирование и смешанная пространственно-временнАя фильтрация
function Medium_Motion_Filter(clip c)
{
&nbsp; c = FluxSmooth(c, 7, 7)
&nbsp; c = BicubicResize(c, 512, 272, 0.00, 0.50)
&nbsp; return c
}

# фильтрация для большого количества движения
# -&gt; смягчающее масштабирование и только пространственная фильтрация
function High_Motion_Filter(clip c)
{
&nbsp; c = FluxSmooth(c, -1, 14)
&nbsp; c = UnFilter(c, -30, -30)
&nbsp; c = BilinearResize(c, 512, 272)
&nbsp; return c
}

# открываем исходный клип
AviSource(&quot;E:\temp\QMF\britney-I_love_rock_'n_roll.avi&quot;)
ConvertToYV12(interlaced=true)
Telecide(0)

# ...и применяем адаптивную фильтрацию (с использованием QMF)
QMF()

----------------------------------------------------
<b>текст файла qmf.avs</b>
----------------------------------------------------

# QUANTIFIED MOTION FILTER (17/08/2003) by HomiE FR (homie.fr@wanadoo.fr)
# Функция определения движения
function ME()
{
&nbsp; # определяем количество движения согласно средней разнице кадров [1]
&nbsp; <b>global motion_level</b> = (<b>diff</b> &lt; threshold_lm) ? 0 : motion_level
&nbsp; <b>global motion_level</b> = (<b>diff</b> &gt;= threshold_lm &amp;&amp; <b>diff</b> &lt;= threshold_hm) ? 1 : motion_level
&nbsp; <b>global motion_level</b> = (<b>diff</b> &gt; threshold_hm) ? 2 : motion_level
}

# функция адаптивной фильтрации
function QMF(clip c, float &quot;threshold_lm&quot;, float &quot;threshold_hm&quot;, bool &quot;debug&quot;)
{
&nbsp; # устанавливаем пороговые значения для количества движения [2]
&nbsp; threshold_lm = default(threshold_lm, 4.0)
&nbsp; threshold_hm = default(threshold_hm, 12.0)
&nbsp; global threshold_lm = threshold_lm
&nbsp; global threshold_hm = threshold_hm

&nbsp; # разрешаем/запрещаем вывод отладочной информации [3]
&nbsp; debug = default(debug, false)

&nbsp; # инициализируем переменную, содержащую количество движения
&nbsp; global motion_level = 0

&nbsp; # инициализируем входной клип [4]
&nbsp; global clip = c

&nbsp; # получаем выходное разрешение [5]
&nbsp; width = Width(Low_Motion_Filter(c))
&nbsp; height = Height(Low_Motion_Filter(c))
&nbsp; global c_resized = PointResize(c, width, height)

&nbsp; # применяем филтр согласно количеству движения [6]
&nbsp; c = ConditionalFilter(c, Low_Motion_Filter(c), c_resized, &quot;<b>motion_level</b>&quot;, &quot;=&quot;, &quot;0&quot;)&nbsp; # [6a]
&nbsp; c = ConditionalFilter(c, Medium_Motion_Filter(c), c, &quot;<b>motion_level</b>&quot;, &quot;=&quot;, &quot;1&quot;)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # [6b]
&nbsp; c = ConditionalFilter(c, High_Motion_Filter(c), c, &quot;<b>motion_level</b>&quot;, &quot;=&quot;, &quot;2&quot;)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # [6c]

&nbsp; # печатаем отладочную информацию (если необходимо) [7]
&nbsp; c = (debug == true) ? ScriptClip(c, &quot;Debug()&quot;) : c

&nbsp; # получаем количество движения из анализа кадров [8]
&nbsp; c = FrameEvaluate(c, &quot;ME()&quot;)

&nbsp; # получаем разницу между предыдущим и текущим кадром [9]
&nbsp; c = FrameEvaluate(c, &quot;<b>global diff</b> = 0.50*YDifferenceFromPrevious(clip) + 0.25*UDifferenceFromPrevious(clip) + 0.25*VDifferenceFromPrevious(clip)&quot;)
&nbsp; return c
}

# функция вывода отладочной информации
function Debug(clip c)
{
&nbsp; # информация о версии [10]
&nbsp; c = Subtitle(c, &quot;Quantified Motion Filter&quot;, x=20, y=30, font=&quot;lucida console&quot;, size=18, text_color=$FFFFFF)
&nbsp; c = Subtitle(c, &quot;by HomiE FR (homie.fr@wanadoo.fr)&quot;, x=20, y=45, font=&quot;lucida console&quot;, size=14, text_color=$FFFFFF)

&nbsp; # информация о количестве движения [11]
&nbsp; c = Subtitle(c, &quot;motion estimation&quot;, x=20, y=85, font=&quot;lucida console&quot;, size=18, text_color=$FFFFFF)
&nbsp; c = Subtitle(c, &quot;diff = &quot;+string(<b>diff</b>), x=20,y=110, font=&quot;lucida console&quot;, size=16, text_color=$FFCCCC)

&nbsp; # информация о режиме работы Quantified Motion Filter [12]
&nbsp; c = Subtitle(c, &quot;quantified motion filter&quot;, x=20, y=135, font=&quot;lucida console&quot;, size=18, text_color=$FFFFFF)
&nbsp; c = (<b>motion_level</b> == 0) ? Subtitle(c, &quot;scene type = low motion&quot;, x=20, y=160, font=&quot;lucida console&quot;, size=16, text_color=$66FF66) : c
&nbsp; c = (<b>motion_level</b> == 1) ? Subtitle(c, &quot;scene type = medium motion&quot;, x=20, y=160, font=&quot;lucida console&quot;, size=16, text_color=$66FF66) : c
&nbsp; c = (<b>motion_level</b> == 2) ? Subtitle(c, &quot;scene type = high motion&quot;, x=20, y=160, font=&quot;lucida console&quot;, size=16, text_color=$66FF66) : c
&nbsp; return c
}
----------------------------------------------------</pre>
Эта цепочка фильтров работает следующим образом:
<ul>
<li>
Когда Vdub запрашивает кадр, AviSynth запрашивает его у QMF.</li>

<ul>
<li>
QMF запрашивает кадр у FrameEvaluate [9].</li>

<li>
После этого вычисляется скрипт [9], и глобальная переменная <i>diff</i>
получает значение после запрашивания кадра у AviSource. FrameEvaluate [9]
запрашивает кадр у FrameEvaluate [8].</li>

<li>
Вычисляется скрипт [8]:</li>

<ul>
<li>
при вычислении me() получает значение глобальная переменная <i>motion_level</i> для этого кадра [1]</li>
</ul>

<li>
Если debug=true, запрашивается кадр у ScriptClip [7] и, соответственно, у Debug().</li>

<li>
После этого (либо если debug=false) запрашивается кадр у последнего оператора ConditionalFilter [6c], 
который запрашивает его у [6b], а тот, в свою очередь, у [6a].</li>

<ul>
<li>
В конечном итоге, запрашивается кадр либо у High_Motion_filter, либо у Medium_Motion_filter, либо у
Low_Motion_filter, в зависимости от значения <i>motion_level</i>.</li>
</ul>
</ul>

<li>
QMF запрашивает кадр у Telecide, Telecide – у ConvertToYV12, и, наконец,
ConvertToYV12 – у AviSource.</li>

<li>
AviSource создаёт кадр, отдаёт его ConvertToYV12, и цепочка развёртывается обратно.</li>
</ul>
<p>Некоторые детали были опущены, но общий смысл работы этого скрипта именно такой.</p>

<p><kbd>$English Date: 2008/12/07 16:36:28 $<br>
Русский перевод 28.05.2005 Eugene Vasiliev (eugvas<span>&#64;</span>mccme.ru)<br>
Обновление 11.09.2008-10.12.2008 Fizick </kbd></p>
<form><input TYPE="Button" VALUE="Back"
onClick="history.go(-1)"></form>
</body>
</html>